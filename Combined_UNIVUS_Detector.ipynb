{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univus Pass detector\n",
    "Detects if a univus pass is fake, expired, invalid, or ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Turn off GPU computiation for tensorflow\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Conversion and formatting to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a video into a series of images\n",
    "def video_to_images(input_video_path):\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat image to correct format for Red/Green detection\n",
    "def format_image(img):\n",
    "    new_horz=720\n",
    "    new_vert=1280\n",
    "    # Resize image\n",
    "    resized_image = img.resize((new_horz, new_vert))\n",
    "    rgb_image =  resized_image.convert('RGB')\n",
    "    formatted_image_name = './prediction_temp/greenred.jpg'\n",
    "    rgb_image.save(formatted_image_name, 'JPEG')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of green or red passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts if image is red or green\n",
    "def predict_green_red_pass(model):\n",
    "    # Reads in BGR, need convert to RGB\n",
    "    img = cv2.imread('./prediction_temp/greenred.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    prediction =  model.predict(np.array([img]))\n",
    "    # Red = 0, Green = 1\n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR for date retrieval from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pytesseract\n",
    "\n",
    "# Extracts text from images using Tesseract OCR\n",
    "def extract_text_from_image(img):\n",
    "    texts = []\n",
    "    # Convert to grayscale image for better performance\n",
    "    grayscale_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # PSM11 = Sparse text, default engine\n",
    "    text = pytesseract.image_to_string(grayscale_image, config='--psm 11 --oem 3')\n",
    "    texts.append(text)\n",
    "    return (texts)\n",
    "    \n",
    "# Uses regex patterns to match time and date\n",
    "def extract_time_date_data(text):\n",
    "    date = re.findall(r'\\d{4}\\s\\w{3,4}\\s\\d{1,2}', text) # Detect format of YYYY MMM DD\n",
    "    time = re.findall(r'\\d{2}:\\d{2}:\\d{2}', text) # Detect format of HH:MM:SS\n",
    "    return (date, time)\n",
    "\n",
    "# Parse strings into date time objects\n",
    "def parse_date_time_data(date, time):\n",
    "    default_date = '2020 Jan 01'\n",
    "    default_time = '00:00:00'\n",
    "    if len(date) == 0:\n",
    "        date.append(default_date)\n",
    "    if len(time) == 0:\n",
    "        time.append(default_time)\n",
    "    date_time_string = date[0] + ' ' + time[0]\n",
    "    date_time_object = datetime.strptime(date_time_string, \"%Y %b %d %H:%M:%S\")\n",
    "    # print(\"Date time =\", date_time_object)\n",
    "    return date_time_object\n",
    "\n",
    "# Determines if time is within threshold. Outputs 1 if within, 0 if not\n",
    "def check_datetime_in_window(date_time_object):\n",
    "    # 86400 seconds in a day\n",
    "    threshold = 600 # Time in seconds\n",
    "\n",
    "    timezone_offset = +8.0  # SG GMT +8\n",
    "    timezone_info = timezone(timedelta(hours=timezone_offset))\n",
    "    datetime.now(timezone_info)\n",
    "    now = datetime.now()\n",
    "    difference = now - date_time_object # Calculate difference in current time vs image\n",
    "    \n",
    "    # Need to update to score based on if days was missing/time was missing\n",
    "    # 1 for within threshold, 0 for missing data, -1 for not in\n",
    "    if difference.total_seconds() < threshold:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Main function to determine if image within time period\n",
    "def determine_time_validity(img):\n",
    "    extract_data = extract_text_from_image(img)\n",
    "    for text in extract_data:\n",
    "        date_time = extract_time_date_data(text)\n",
    "        date_time_object = parse_date_time_data(date_time[0], date_time[1])\n",
    "        return check_datetime_in_window(date_time_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO Model for motion tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def aggregate_velocity(change_rates):\n",
    "    if len(change_rates) == 0:\n",
    "        return\n",
    "    total_change = 0\n",
    "    isFirst = True\n",
    "    for rate in change_rates:\n",
    "        if isFirst:\n",
    "            isFirst = False\n",
    "            continue\n",
    "        total_change += rate\n",
    "    return total_change/len(change_rates)\n",
    "\n",
    "def aggregate_direction(directions):\n",
    "    horizontal_count = 0\n",
    "    vertical_count = 0\n",
    "    static_count = 0\n",
    "    no_direction = 0\n",
    "    for direction in directions:\n",
    "        if direction == 'Horizontal':\n",
    "            horizontal_count += 1\n",
    "        elif direction == 'Vertical':\n",
    "            vertical_count += 1\n",
    "        elif direction == 'Static':\n",
    "            static_count += 1\n",
    "        else:\n",
    "            no_direction += 1\n",
    "    if static_count > horizontal_count and static_count > vertical_count:\n",
    "        return 'Static'\n",
    "    if no_direction > horizontal_count and no_direction > vertical_count:\n",
    "        return 'No Logo Detectable'\n",
    "    if horizontal_count > vertical_count:\n",
    "        return 'Horizontal'\n",
    "    return 'Vertical'\n",
    "\n",
    "def get_logo_speed(velocity):\n",
    "    if velocity == None:\n",
    "        return 'No Speed'\n",
    "    if velocity < 10:\n",
    "        return 'Normal Speed'\n",
    "    else:\n",
    "        return 'Abnormal Fast'\n",
    "\n",
    "# Calculate speed and direction coordinates\n",
    "def calculate_direction(coordinates, prev_X, prev_Y):\n",
    "    movement = ''\n",
    "    rate_of_change = ''\n",
    "    # print('x = ' + str(coordinates[0][0]) + ' ' + 'y = ' + str(coordinates[0][1]))\n",
    "    # Focus on a single logo\n",
    "    newX = coordinates[0][0]\n",
    "    newY = coordinates[0][1]\n",
    "    change_in_position_x = abs(newX - prev_X)\n",
    "    change_in_position_y = abs(newY - prev_Y)\n",
    "    if change_in_position_x < 1 and change_in_position_y < 1:\n",
    "        movement = 'Static'\n",
    "        rate_of_change = 0\n",
    "    elif change_in_position_y < change_in_position_x:\n",
    "        movement = 'Horizontal'\n",
    "        rate_of_change = change_in_position_x\n",
    "    else:\n",
    "        movement = 'Vertical'\n",
    "        rate_of_change = change_in_position_y\n",
    "    if rate_of_change > 100:\n",
    "        rate_of_change /= 100\n",
    "    return newX, newY, movement, rate_of_change\n",
    "\n",
    "def predict_speed_direction(model, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_movement_sets = 10\n",
    "    frame_limit = 5\n",
    "    previous_x = 0\n",
    "    previous_y = 0\n",
    "    movement_sets = 0\n",
    "    frame_count = 0\n",
    "    change_rates = []\n",
    "    directions = []\n",
    "    while cap.isOpened() and movement_sets < total_movement_sets:\n",
    "        ret, frame = cap.read()\n",
    "        # Make Detections\n",
    "        results = model(frame)\n",
    "        # cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "        if frame_count == frame_limit:\n",
    "            # xyxy = xmin, ymin, xmax, ymax, confidence, class\n",
    "            coordinates = results.xyxy[0]\n",
    "            detections = len(coordinates)\n",
    "            if detections != 0:\n",
    "                newX, newY, direction, change_rate = calculate_direction(coordinates, previous_x, previous_y)\n",
    "                previous_x = newX\n",
    "                previous_y = newY\n",
    "                directions.append(direction)\n",
    "                change_rates.append(change_rate)\n",
    "            else:\n",
    "                print('Unable to Detect Images')\n",
    "                directions.append('NO IMAGE')\n",
    "            movement_sets += 1\n",
    "            frame_count = 0\n",
    "        frame_count += 1\n",
    "        # Exit loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    average_velocity = aggregate_velocity(change_rates)\n",
    "    predicted_direction = aggregate_direction(directions)\n",
    "    return average_velocity, predicted_direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry out predictions\n",
    "def predict_pass(input_video_path, green_red_model, yolo_model):\n",
    "    outputs = []\n",
    "    # Convert input video into a series of screenshots\n",
    "    images = video_to_images(input_video_path)\n",
    "    # Save a raw image to the prediction_temp folder for use\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    # Determine movement metrics\n",
    "    velocity, direction = predict_speed_direction(yolo_model, input_video_path)\n",
    "    speed_rating = get_logo_speed(velocity)\n",
    "    if direction == 'Horizontal':\n",
    "        print('Logo movement in correct direction: ' + direction)\n",
    "        outputs.append(1)\n",
    "    else:\n",
    "        print('Improper logo movement detected: ' + direction + ', expected Horizontal')\n",
    "        outputs.append(0)\n",
    "    if speed_rating == 'Normal Speed':\n",
    "        print('Normal logo speed detected')\n",
    "        outputs.append(1)\n",
    "    else:\n",
    "        print('Logo speed anomaly: ' + speed_rating)\n",
    "        outputs.append(0)\n",
    "\n",
    "    # Select image to be used for green-red detection and OCR\n",
    "    img = Image.open('./RawImages/GreenPass/2.png')\n",
    "    format_image(img)\n",
    "    green_red_prediction = predict_green_red_pass(green_red_model)\n",
    "    outputs.append(green_red_prediction)\n",
    "    if green_red_prediction == 0:\n",
    "        print('Pass Colour: Red')\n",
    "    elif green_red_prediction == 1:\n",
    "        print('Pass Colour: Green')\n",
    "\n",
    "    img = cv2.imread('./RawImages/GreenPass/2.png')\n",
    "    is_datetime_valid = determine_time_validity(img)\n",
    "    outputs.append(is_datetime_valid)\n",
    "    if is_datetime_valid == 1:\n",
    "        print('Date time is valid')\n",
    "    elif is_datetime_valid == 0:\n",
    "        print('Expired Pass Detected')\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\dojh1/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-4-4 torch 1.8.2+cu111 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7055974 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Load in pre-trained models\n",
    "green_red_model = models.load_model('GreenRedClassifier.model')\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path='./TrainedYoloModel/best3.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Improper logo movement detected: Vertical, expected Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Red\n",
      "Expired Pass Detected\n",
      "-----------------------------------\n",
      "[0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predict_pass('./Videos/Vertical.mp4', green_red_model, yolo_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21df0356f9123b9ffe2140fcee819cd2cf32077b8756437e0847ceff6279ac46"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
