{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generator\n",
    "Creates dataset for training of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Turn off GPU computiation for tensorflow\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Conversion and formatting to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a video into a series of images\n",
    "def video_to_images(input_loc):\n",
    "    vidcap = cv2.VideoCapture(input_loc)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    output_loc =  './prediction_temp/VideoFrames/'\n",
    "    filename = 'frame1'\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1000))    # added this line \n",
    "    success,image = vidcap.read()\n",
    "    cv2.imwrite(output_loc + f\"\\\\{filename}.jpg\", image)     # save frame as JPEG file\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat image to correct format for Red/Green detection\n",
    "def format_image(img):\n",
    "    new_horz=720\n",
    "    new_vert=1280\n",
    "    # Resize image\n",
    "    resized_image = img.resize((new_horz, new_vert))\n",
    "    rgb_image =  resized_image.convert('RGB')\n",
    "    formatted_image_name = './prediction_temp/greenred.jpg'\n",
    "    rgb_image.save(formatted_image_name, 'JPEG')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of green or red passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts if image is red or green\n",
    "def predict_green_red_pass(model):\n",
    "    # Reads in BGR, need convert to RGB\n",
    "    img = cv2.imread('./prediction_temp/greenred.jpg')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    prediction =  model.predict(np.array([img]))\n",
    "    # Red = 0, Green = 1\n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR for date retrieval from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pytesseract\n",
    "\n",
    "# Extracts text from images using Tesseract OCR\n",
    "def extract_text_from_image(img):\n",
    "    texts = []\n",
    "    # Convert to grayscale image for better performance\n",
    "    grayscale_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # PSM11 = Sparse text, default engine\n",
    "    text = pytesseract.image_to_string(grayscale_image, config='--psm 11 --oem 3')\n",
    "    texts.append(text)\n",
    "    return (texts)\n",
    "    \n",
    "# Uses regex patterns to match time and date\n",
    "def extract_time_date_data(text):\n",
    "    date = re.findall(r'\\d{4}\\s\\w{3,4}\\s\\d{1,2}', text) # Detect format of YYYY MMM DD\n",
    "    time = re.findall(r'\\d{2}:\\d{2}:\\d{2}', text) # Detect format of HH:MM:SS\n",
    "    return (date, time)\n",
    "\n",
    "# Parse strings into date time objects\n",
    "def parse_date_time_data(date, time):\n",
    "    default_date = '2020 Jan 01'\n",
    "    default_time = '00:00:00'\n",
    "    if len(date) == 0:\n",
    "        date.append(default_date)\n",
    "    if len(time) == 0:\n",
    "        time.append(default_time)\n",
    "    date_time_string = date[0] + ' ' + time[0]\n",
    "    date_time_object = datetime.strptime(date_time_string, \"%Y %b %d %H:%M:%S\")\n",
    "    # print(\"Date time =\", date_time_object)\n",
    "    return date_time_object\n",
    "\n",
    "# Determines if time is within threshold. Outputs 1 if within, 0 if not\n",
    "def check_datetime_in_window(date_time_object):\n",
    "    # 86400 seconds in a day\n",
    "    threshold = 86400 # Time in seconds\n",
    "\n",
    "    timezone_offset = +8.0  # SG GMT +8\n",
    "    timezone_info = timezone(timedelta(hours=timezone_offset))\n",
    "    datetime.now(timezone_info)\n",
    "    now = datetime.now()\n",
    "    difference = now - date_time_object # Calculate difference in current time vs image\n",
    "    \n",
    "    # Need to update to score based on if days was missing/time was missing\n",
    "    # 1 for within threshold and -1 for not in\n",
    "    if difference.total_seconds() < threshold:\n",
    "        return 1\n",
    "    else: \n",
    "        return -1\n",
    "\n",
    "# Main function to determine if image within time period\n",
    "def determine_time_validity(img):\n",
    "    extract_data = extract_text_from_image(img)\n",
    "    for text in extract_data:\n",
    "        date_time = extract_time_date_data(text)\n",
    "        if len(date_time[0]) != 0 and len(date_time[1]) != 0:\n",
    "            date_time_object = parse_date_time_data(date_time[0], date_time[1])\n",
    "            return check_datetime_in_window(date_time_object)\n",
    "        else:\n",
    "            return 0 # return 0 for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO Model for motion tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def aggregate_velocity(change_rates):\n",
    "    # print(change_rates)\n",
    "    if len(change_rates) == 0:\n",
    "        return\n",
    "    abnormalSpeed = 0\n",
    "    isFirst = True\n",
    "    for rate in change_rates:\n",
    "        if isFirst:\n",
    "            isFirst = False\n",
    "            continue\n",
    "        if rate > 15:\n",
    "            abnormalSpeed += 1\n",
    "    return abnormalSpeed\n",
    "\n",
    "def aggregate_direction(directions):\n",
    "    horizontal_count = 0\n",
    "    vertical_count = 0\n",
    "    static_count = 0\n",
    "    no_direction = 0\n",
    "    for direction in directions:\n",
    "        if direction == 'Horizontal':\n",
    "            horizontal_count += 1\n",
    "        elif direction == 'Vertical':\n",
    "            vertical_count += 1\n",
    "        elif direction == 'Static':\n",
    "            static_count += 1\n",
    "        else:\n",
    "            no_direction += 1\n",
    "    if static_count > horizontal_count and static_count > vertical_count:\n",
    "        return 'Static'\n",
    "    if no_direction > horizontal_count and no_direction > vertical_count:\n",
    "        return 'No Logo Detectable'\n",
    "    if horizontal_count > vertical_count:\n",
    "        return 'Horizontal'\n",
    "    return 'Vertical'\n",
    "\n",
    "def get_logo_speed(velocity):\n",
    "    if velocity == None:\n",
    "        return 'No Speed'\n",
    "    if velocity <= 4:\n",
    "        return 'Normal Speed'\n",
    "    else:\n",
    "        return 'Abnormal Fast'\n",
    "\n",
    "# Calculate speed and direction coordinates\n",
    "def calculate_direction(coordinates, prev_X, prev_Y):\n",
    "    movement = ''\n",
    "    rate_of_change = ''\n",
    "    # print('x = ' + str(coordinates[0][0]) + ' ' + 'y = ' + str(coordinates[0][1]))\n",
    "    # Focus on a single logo\n",
    "    newX = coordinates[0][0]\n",
    "    newY = coordinates[0][1]\n",
    "    change_in_position_x = abs(newX - prev_X)\n",
    "    change_in_position_y = abs(newY - prev_Y)\n",
    "    if change_in_position_x < 1 and change_in_position_y < 1:\n",
    "        movement = 'Static'\n",
    "        rate_of_change = 0\n",
    "    elif change_in_position_y < change_in_position_x:\n",
    "        movement = 'Horizontal'\n",
    "        rate_of_change = change_in_position_x\n",
    "    else:\n",
    "        movement = 'Vertical'\n",
    "        rate_of_change = change_in_position_y\n",
    "    if rate_of_change > 100:\n",
    "        rate_of_change /= 100\n",
    "    return newX, newY, movement, rate_of_change\n",
    "\n",
    "def predict_speed_direction(model, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_movement_sets = 10\n",
    "    frame_limit = 5\n",
    "    previous_x = 0\n",
    "    previous_y = 0\n",
    "    movement_sets = 0\n",
    "    frame_count = 0\n",
    "    change_rates = []\n",
    "    directions = []\n",
    "    while cap.isOpened() and movement_sets < total_movement_sets:\n",
    "        ret, frame = cap.read()\n",
    "        # Make Detections\n",
    "        results = model(frame)\n",
    "        # cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "        if frame_count == frame_limit:\n",
    "            # xyxy = xmin, ymin, xmax, ymax, confidence, class\n",
    "            coordinates = results.xyxy[0]\n",
    "            detections = len(coordinates)\n",
    "            if detections != 0:\n",
    "                newX, newY, direction, change_rate = calculate_direction(coordinates, previous_x, previous_y)\n",
    "                previous_x = newX\n",
    "                previous_y = newY\n",
    "                directions.append(direction)\n",
    "                change_rates.append(change_rate)\n",
    "            else:\n",
    "                directions.append('NO IMAGE')\n",
    "            movement_sets += 1\n",
    "            frame_count = 0\n",
    "        frame_count += 1\n",
    "        # Exit loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    average_velocity = aggregate_velocity(change_rates)\n",
    "    predicted_direction = aggregate_direction(directions)\n",
    "    return average_velocity, predicted_direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FakeRealClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fake_real_pass(model):\n",
    "    # read in img in the required format\n",
    "    img = tf.keras.preprocessing.image.load_img('./prediction_temp/VideoFrames/frame1.jpg', color_mode = \"grayscale\", target_size=(480,480))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(img)/255\n",
    "    input_arr = np.array([input_arr])\n",
    "    # make predictions\n",
    "    predictions = model.predict(input_arr)\n",
    "    # Fake = 0, Real = 1\n",
    "    return np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry out predictions\n",
    "def predict_pass(input_video_path, green_red_model, yolo_model, fake_real_model):\n",
    "    outputs = []\n",
    "    # Convert input video into a series of screenshots\n",
    "    video_to_images(input_video_path)\n",
    "    # Save a raw image to the prediction_temp folder for use\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    # Determine movement metrics\n",
    "    velocity, direction = predict_speed_direction(yolo_model, input_video_path)\n",
    "    speed_rating = get_logo_speed(velocity)\n",
    "    if direction == 'Horizontal':\n",
    "        print('Logo movement in correct direction: ' + direction)\n",
    "        outputs.append(1)\n",
    "    else:\n",
    "        print('Improper logo movement detected: ' + direction + ', expected Horizontal')\n",
    "        outputs.append(0)\n",
    "    if speed_rating == 'Normal Speed':\n",
    "        print('Normal logo speed detected')\n",
    "        outputs.append(1)\n",
    "    else:\n",
    "        print('Logo speed anomaly: ' + speed_rating)\n",
    "        outputs.append(0)\n",
    "\n",
    "    # Select image to be used for green-red detection and OCR + fake-real detection\n",
    "    img = Image.open('./prediction_temp/VideoFrames/frame1.jpg')\n",
    "    format_image(img)\n",
    "    green_red_prediction = predict_green_red_pass(green_red_model)\n",
    "    outputs.append(green_red_prediction)\n",
    "    if green_red_prediction == 0:\n",
    "        print('Pass Colour: Red')\n",
    "    elif green_red_prediction == 1:\n",
    "        print('Pass Colour: Green')\n",
    "\n",
    "    # path is specified in the func itself for now\n",
    "    fake_real_prediction = predict_fake_real_pass(fake_real_model)\n",
    "    outputs.append(fake_real_prediction)\n",
    "    if fake_real_prediction == 0:\n",
    "        print('Pass Status: Fake')\n",
    "    elif fake_real_prediction == 1:\n",
    "        print('Pass Status: Real')\n",
    "\n",
    "    img = cv2.imread('./prediction_temp/VideoFrames/frame1.jpg')\n",
    "    is_datetime_valid = determine_time_validity(img)\n",
    "    outputs.append(is_datetime_valid)\n",
    "    if is_datetime_valid == 1:\n",
    "        print('Date time is valid')\n",
    "    elif is_datetime_valid == 0:\n",
    "        print('Missing Date Time Data')\n",
    "    elif is_datetime_valid == -1:\n",
    "        print('Expired Date time detected')\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\dojh1/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-4-8 torch 1.8.2+cu111 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7055974 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Load in pre-trained models\n",
    "green_red_model = models.load_model('GreenRedClassifier.model')\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path='./TrainedYoloModel/best3.pt', force_reload=True)\n",
    "fake_real_model = models.load_model('./FakePassModel/fakepass_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Improper logo movement detected: Static, expected Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Real\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "outputs = predict_pass('./Videos/StaticVideo.mp4', green_red_model, yolo_model, fake_real_model)\n",
    "\n",
    "# Valid and Invalid\n",
    "# Valid, Red Pass (invalid), Fake\n",
    "# 1, 0, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to create test sets\n",
    "We will be taking 20% as TEST SET\n",
    "and 20% from the remaining 80% as VALIDATION\n",
    "\n",
    "Test Data:\n",
    "- +ve - 6 for Testing, 19 for training, 5 for validation, Total 30\n",
    "- Fake - 3 for Testing, 8 for training, 2 for validation, Total 13\n",
    "- Vertical - 1 for Testing, 4 for training, 1 for validation, Total 6\n",
    "- Red - 2 for Testing, 5 for training, 3 for validation, Total 10\n",
    "\n",
    "Data output columns:\n",
    "- isCorrectDirection\n",
    "- isCorrectSpeed\n",
    "- isGreenPass\n",
    "- isRealPass\n",
    "- isNotExpired (Expired, Not sure, Valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_and_save_dataset(input_path, output_path, start_number, end_number):\n",
    "    training_set_df = pd.DataFrame(columns=['isCorrectDirection', 'isCorrectSpeed', 'isGreenPass', 'isRealPass', 'isNotExpired', 'Label'])\n",
    "    for i in range(start_number, end_number+1):\n",
    "        input_loc = input_path + str(i) + '.mp4'\n",
    "        outputs = predict_pass(input_loc, green_red_model, yolo_model, fake_real_model)\n",
    "        outputs.append(-1)\n",
    "        training_set_df.loc[len(training_set_df)] = outputs\n",
    "    training_set_df.to_csv(output_path, index=False, index_label=None)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Logo movement in correct direction: Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Logo movement in correct direction: Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Logo movement in correct direction: Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Logo movement in correct direction: Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Improper logo movement detected: Static, expected Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Logo movement in correct direction: Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Logo movement in correct direction: Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Logo movement in correct direction: Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Logo movement in correct direction: Horizontal\n",
      "Normal logo speed detected\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Improper logo movement detected: No Logo Detectable, expected Horizontal\n",
      "Logo speed anomaly: No Speed\n",
      "Pass Colour: Green\n",
      "Pass Status: Fake\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "create_and_save_dataset('../Test Data/Fake/fake', '../Test Data/Fake/FakeSet.csv', 1, 10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21df0356f9123b9ffe2140fcee819cd2cf32077b8756437e0847ceff6279ac46"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
